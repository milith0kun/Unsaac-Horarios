# Sistema de GestiÃ³n de Horarios UNSAAC

## DescripciÃ³n del Proyecto

Sistema web para la gestiÃ³n y generaciÃ³n de horarios acadÃ©micos de la Universidad Nacional de San Antonio Abad del Cusco (UNSAAC). Permite a docentes y estudiantes consultar, generar y gestionar horarios de cursos con detecciÃ³n automÃ¡tica de cruces horarios.

## ğŸ¯ Objetivos

- **ExtracciÃ³n automatizada** de datos de horarios mediante web scraping
- **GestiÃ³n centralizada** de horarios en base de datos
- **Interfaz intuitiva** para selecciÃ³n de cursos
- **GeneraciÃ³n automÃ¡tica** de horarios personalizados
- **DetecciÃ³n de conflictos** y cruces horarios
- **VisualizaciÃ³n clara** de horarios semanales

## ğŸš€ CÃ³mo Empezar - Plan de Web Scraping

### ğŸ“‹ AnÃ¡lisis Previo y Reconocimiento

Antes de implementar cualquier cÃ³digo, necesitamos realizar un anÃ¡lisis exhaustivo de las fuentes de datos de UNSAAC:

#### 1. **IdentificaciÃ³n de Fuentes de Datos**
- **Portal AcadÃ©mico Principal**: `https://www.unsaac.edu.pe/`
- **Sistema de MatrÃ­cula**: Identificar URLs especÃ­ficas de cada facultad
- **PÃ¡ginas de Facultades**: Analizar estructura de cada escuela profesional
- **Sistemas Internos**: Verificar si existen APIs pÃºblicas o endpoints accesibles

#### 2. **Reconocimiento de Estructura Web**
```
Tareas de AnÃ¡lisis:
â”œâ”€â”€ InspecciÃ³n manual de pÃ¡ginas objetivo
â”œâ”€â”€ IdentificaciÃ³n de patrones HTML/CSS
â”œâ”€â”€ AnÃ¡lisis de JavaScript dinÃ¡mico
â”œâ”€â”€ DetecciÃ³n de sistemas de autenticaciÃ³n
â”œâ”€â”€ Mapeo de rutas y endpoints
â””â”€â”€ IdentificaciÃ³n de limitaciones (CAPTCHA, rate limits)
```

#### 3. **Estrategia de ExtracciÃ³n por Fases**

**Fase 1: Reconocimiento Pasivo (1-2 dÃ­as)**
- NavegaciÃ³n manual de portales UNSAAC
- DocumentaciÃ³n de estructura de pÃ¡ginas
- IdentificaciÃ³n de tablas de horarios
- AnÃ¡lisis de formularios de bÃºsqueda
- Mapeo de URLs por facultad/escuela

**Fase 2: AnÃ¡lisis TÃ©cnico (2-3 dÃ­as)**
- InspecciÃ³n de cÃ³digo fuente HTML
- IdentificaciÃ³n de selectores CSS/XPath
- AnÃ¡lisis de requests de red (DevTools)
- DetecciÃ³n de contenido dinÃ¡mico (AJAX)
- EvaluaciÃ³n de medidas anti-scraping

**Fase 3: Prototipo de ExtracciÃ³n (3-4 dÃ­as)**
- Desarrollo de scraper bÃ¡sico para una facultad
- Pruebas de extracciÃ³n de datos
- ValidaciÃ³n de informaciÃ³n obtenida
- OptimizaciÃ³n de selectores
- ImplementaciÃ³n de manejo de errores

### ğŸ¯ MetodologÃ­a de Scraping

#### **Enfoque Gradual y Respetuoso**

1. **AnÃ¡lisis de robots.txt**
   - Verificar polÃ­ticas de scraping permitidas
   - Respetar directivas de exclusiÃ³n
   - Identificar crawl-delay recomendado

2. **Estrategia de Rate Limiting**
   ```
   ConfiguraciÃ³n Propuesta:
   â”œâ”€â”€ Delay entre requests: 2-5 segundos
   â”œâ”€â”€ Requests por minuto: mÃ¡ximo 10-15
   â”œâ”€â”€ Horarios de scraping: 2:00 AM - 5:00 AM
   â”œâ”€â”€ RotaciÃ³n de User-Agents
   â””â”€â”€ ImplementaciÃ³n de backoff exponencial
   ```

3. **Manejo de Contenido DinÃ¡mico**
   - Uso de Puppeteer para JavaScript rendering
   - Espera de elementos especÃ­ficos
   - Manejo de lazy loading
   - Captura de requests AJAX

#### **Estructura de Datos Objetivo**

```javascript
// Estructura esperada por curso
{
  codigo: "CS101",
  nombre: "IntroducciÃ³n a la ProgramaciÃ³n",
  creditos: 4,
  facultad: "IngenierÃ­a",
  escuela: "IngenierÃ­a InformÃ¡tica",
  docente: "Dr. Juan PÃ©rez",
  horarios: [
    {
      dia: "Lunes",
      horaInicio: "08:00",
      horaFin: "10:00",
      aula: "Lab-101",
      tipo: "TeorÃ­a",
      grupo: "A"
    }
  ],
  semestre: "2024-I",
  requisitos: ["MAT101"],
  cupos: {
    total: 30,
    ocupados: 25,
    disponibles: 5
  }
}
```

### ğŸ› ï¸ Herramientas y TecnologÃ­as

#### **Stack de Scraping**
- **Puppeteer**: NavegaciÃ³n automatizada y rendering de JavaScript
- **Cheerio**: Parsing eficiente de HTML estÃ¡tico
- **Axios**: Requests HTTP optimizados
- **Playwright**: Alternativa robusta para sitios complejos
- **Proxy-chain**: RotaciÃ³n de IPs si es necesario

#### **Almacenamiento y Procesamiento**
- **PostgreSQL**: Base de datos principal para horarios
- **Redis**: Cache temporal y queue de jobs
- **Bull Queue**: GestiÃ³n de trabajos de scraping
- **Winston**: Logging detallado de operaciones

#### **Monitoreo y Alertas**
- **Prometheus + Grafana**: MÃ©tricas de scraping
- **Sentry**: Tracking de errores
- **Nodemailer**: Notificaciones por email
- **Slack/Discord Webhooks**: Alertas en tiempo real

### ğŸ“Š Plan de ValidaciÃ³n

#### **VerificaciÃ³n de Datos**
1. **ValidaciÃ³n Cruzada**
   - ComparaciÃ³n con fuentes oficiales
   - VerificaciÃ³n manual de muestras aleatorias
   - DetecciÃ³n de inconsistencias

2. **MÃ©tricas de Calidad**
   ```
   KPIs de Scraping:
   â”œâ”€â”€ Tasa de Ã©xito de extracciÃ³n: >95%
   â”œâ”€â”€ Tiempo promedio por pÃ¡gina: <10s
   â”œâ”€â”€ Datos Ãºnicos extraÃ­dos por dÃ­a: >1000
   â”œâ”€â”€ Errores por cada 100 requests: <2
   â””â”€â”€ Cobertura de facultades: 100%
   ```

3. **DetecciÃ³n de Cambios**
   - Monitoreo de estructura de pÃ¡ginas
   - Alertas por cambios en selectores
   - Versionado de configuraciones de scraping

### ğŸ”„ Cronograma de ImplementaciÃ³n

```
Semana 1: AnÃ¡lisis y Reconocimiento
â”œâ”€â”€ DÃ­as 1-2: ExploraciÃ³n manual de portales
â”œâ”€â”€ DÃ­as 3-4: AnÃ¡lisis tÃ©cnico detallado
â”œâ”€â”€ DÃ­as 5-7: DocumentaciÃ³n de hallazgos

Semana 2: Desarrollo del Scraper
â”œâ”€â”€ DÃ­as 1-3: ImplementaciÃ³n de scraper bÃ¡sico
â”œâ”€â”€ DÃ­as 4-5: Pruebas y refinamiento
â”œâ”€â”€ DÃ­as 6-7: IntegraciÃ³n con base de datos

Semana 3: OptimizaciÃ³n y Escalabilidad
â”œâ”€â”€ DÃ­as 1-3: ImplementaciÃ³n de rate limiting
â”œâ”€â”€ DÃ­as 4-5: Sistema de monitoreo
â”œâ”€â”€ DÃ­as 6-7: Pruebas de carga y estabilidad
```

### âš ï¸ Consideraciones Ã‰ticas y Legales

- **Respeto a tÃ©rminos de servicio** de UNSAAC
- **MinimizaciÃ³n de carga** en servidores universitarios
- **Uso responsable** de datos extraÃ­dos
- **Cumplimiento de GDPR/LOPD** para datos personales
- **Transparencia** con la instituciÃ³n sobre el proyecto

### ğŸ¯ PrÃ³ximos Pasos

1. **Realizar reconocimiento manual** de portales UNSAAC
2. **Documentar estructura** de pÃ¡ginas objetivo
3. **Identificar patrones** de datos de horarios
4. **Evaluar complejidad tÃ©cnica** de cada fuente
5. **Definir prioridades** de implementaciÃ³n por facultad

## ğŸ—ï¸ Arquitectura del Sistema

### Frontend
- **React 18+** - Interfaz de usuario moderna y reactiva
- **TypeScript** - Tipado estÃ¡tico para mayor robustez
- **Tailwind CSS** - DiseÃ±o responsive y moderno
- **React Router** - NavegaciÃ³n SPA
- **Zustand/Redux Toolkit** - GestiÃ³n de estado global
- **React Query** - Manejo de estado del servidor
- **Chart.js/Recharts** - VisualizaciÃ³n de horarios

### Backend
- **Node.js + Express** - Servidor API REST
- **TypeScript** - Consistencia de tipos en todo el stack
- **Prisma ORM** - GestiÃ³n de base de datos
- **JWT** - AutenticaciÃ³n y autorizaciÃ³n
- **Helmet + CORS** - Seguridad de API

### Web Scraping
- **Puppeteer** - AutomatizaciÃ³n de navegador para scraping
- **Cheerio** - Parsing de HTML
- **Cron Jobs** - ActualizaciÃ³n automÃ¡tica de datos
- **Rate Limiting** - Control de frecuencia de requests

### Base de Datos
- **PostgreSQL** - Base de datos principal
- **Redis** - Cache y sesiones
- **Backup automÃ¡tico** - Respaldo de datos crÃ­ticos

## ğŸ“Š Modelo de Datos

### Entidades Principales

```sql
-- Docentes
Teachers {
  id: UUID
  name: String
  email: String
  department: String
  created_at: DateTime
}

-- Cursos
Courses {
  id: UUID
  code: String
  name: String
  credits: Integer
  department: String
  semester: Integer
  created_at: DateTime
}

-- Horarios
Schedules {
  id: UUID
  course_id: UUID
  teacher_id: UUID
  day_of_week: Integer
  start_time: Time
  end_time: Time
  classroom: String
  group: String
  semester: String
  created_at: DateTime
}

-- Usuarios
Users {
  id: UUID
  username: String
  email: String
  role: Enum(student, teacher, admin)
  created_at: DateTime
}

-- Horarios Personalizados
UserSchedules {
  id: UUID
  user_id: UUID
  name: String
  schedules: JSON
  created_at: DateTime
}
```

## ğŸ”§ Funcionalidades

### Para Estudiantes
- âœ… BÃºsqueda de cursos por cÃ³digo, nombre o docente
- âœ… SelecciÃ³n mÃºltiple de cursos
- âœ… GeneraciÃ³n automÃ¡tica de horarios
- âœ… DetecciÃ³n de cruces horarios
- âœ… ExportaciÃ³n de horarios (PDF, imagen)
- âœ… Guardado de horarios favoritos

### Para Docentes
- âœ… VisualizaciÃ³n de horarios asignados
- âœ… GestiÃ³n de disponibilidad
- âœ… Reportes de carga acadÃ©mica

### Para Administradores
- âœ… GestiÃ³n de cursos y docentes
- âœ… ConfiguraciÃ³n de scraping
- âœ… Monitoreo del sistema
- âœ… Respaldos de base de datos

## ğŸš€ TecnologÃ­as de Scraping

### Estrategia de ExtracciÃ³n
1. **Puppeteer** para navegaciÃ³n automatizada
2. **AnÃ¡lisis de patrones** en pÃ¡ginas web de UNSAAC
3. **ExtracciÃ³n de datos** de tablas HTML
4. **ValidaciÃ³n y limpieza** de datos
5. **Almacenamiento estructurado** en base de datos

### Fuentes de Datos
- Portal acadÃ©mico UNSAAC
- Sistemas de matrÃ­cula
- PÃ¡ginas de facultades
- APIs pÃºblicas (si estÃ¡n disponibles)

## ğŸ“± Interfaz de Usuario

### PÃ¡ginas Principales
- **Dashboard** - Resumen de horarios y estadÃ­sticas
- **BÃºsqueda de Cursos** - Filtros avanzados y resultados
- **Generador de Horarios** - SelecciÃ³n y configuraciÃ³n
- **Mis Horarios** - GestiÃ³n de horarios guardados
- **Perfil** - ConfiguraciÃ³n de usuario

### Componentes Clave
- **Calendario Semanal** - VisualizaciÃ³n de horarios
- **Selector de Cursos** - Interfaz de selecciÃ³n mÃºltiple
- **Detector de Conflictos** - Alertas visuales
- **Exportador** - Opciones de descarga

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos
```bash
# Node.js 18+
# PostgreSQL 14+
# Redis 6+
# Git
```

### Variables de Entorno

#### Variables Requeridas
El proyecto requiere las siguientes variables de entorno para funcionar correctamente:

```env
# Base de datos PostgreSQL (Supabase)
# URL de conexiÃ³n principal con pooling para aplicaciones
DATABASE_URL="postgresql://postgres.username:password@host:6543/postgres?pgbouncer=true"

# URL de conexiÃ³n directa para migraciones y operaciones que requieren conexiÃ³n directa
DIRECT_URL="postgresql://postgres.username:password@host:5432/postgres"

# Redis (opcional)
REDIS_URL="redis://localhost:6379"

# JWT
JWT_SECRET="your-secret-key"
JWT_EXPIRES_IN="7d"

# Scraping
SCRAPING_INTERVAL="0 2 * * *"  # Diario a las 2 AM
SCRAPING_TIMEOUT=30000

# Email (opcional)
SMTP_HOST="smtp.gmail.com"
SMTP_PORT=587
SMTP_USER="your-email@gmail.com"
SMTP_PASS="your-app-password"
```

#### ConfiguraciÃ³n Local
1. Copia el archivo `.env.example` como `.env` en la raÃ­z del proyecto
2. Reemplaza los valores de ejemplo con tus credenciales reales
3. AsegÃºrate de que todas las variables requeridas estÃ©n configuradas

#### ConfiguraciÃ³n en Vercel
Para desplegar en Vercel, debes configurar las variables de entorno en el panel de Vercel:

1. **Accede a tu proyecto en Vercel Dashboard**
2. **Navega a Settings > Environment Variables**
3. **Agrega las siguientes variables:**
   - `DATABASE_URL`: URL de conexiÃ³n a PostgreSQL con pooling
   - `DIRECT_URL`: URL de conexiÃ³n directa a PostgreSQL
4. **Selecciona todos los entornos** (Production, Preview, Development)
5. **Guarda los cambios** y redespliega el proyecto

> âš ï¸ **Importante**: Sin estas variables configuradas en Vercel, la aplicaciÃ³n mostrarÃ¡ errores 500 al intentar conectarse a la base de datos.

#### Obtener Credenciales de Supabase
1. Crea un proyecto en [Supabase](https://supabase.com)
2. Ve a Settings > Database
3. Copia la "Connection string" para `DATABASE_URL` (con pooling)
4. Copia la "Direct connection" para `DIRECT_URL`
5. AsegÃºrate de reemplazar `[YOUR-PASSWORD]` con tu contraseÃ±a real

## ğŸ“ˆ Roadmap

### Fase 1 - MVP (4-6 semanas)
- [x] ConfiguraciÃ³n del proyecto
- [ ] DiseÃ±o de base de datos
- [ ] API bÃ¡sica (CRUD)
- [ ] Scraping inicial
- [ ] Frontend bÃ¡sico
- [ ] GeneraciÃ³n simple de horarios

### Fase 2 - Funcionalidades Avanzadas (4-6 semanas)
- [ ] DetecciÃ³n de cruces
- [ ] ExportaciÃ³n de horarios
- [ ] Sistema de usuarios
- [ ] Dashboard administrativo
- [ ] OptimizaciÃ³n de rendimiento

### Fase 3 - Mejoras y Escalabilidad (2-4 semanas)
- [ ] Notificaciones en tiempo real
- [ ] API mÃ³vil
- [ ] AnÃ¡lisis de datos
- [ ] IntegraciÃ³n con sistemas UNSAAC

## ğŸ¤ ContribuciÃ³n

1. Fork del repositorio
2. Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ‘¥ Equipo de Desarrollo

- **Frontend Developer** - React, TypeScript, UI/UX
- **Backend Developer** - Node.js, PostgreSQL, APIs
- **Scraping Specialist** - Puppeteer, Data Extraction
- **DevOps Engineer** - Deployment, Monitoring

## ğŸ“ Contacto

Para preguntas o sugerencias sobre el proyecto:
- Email: desarrollo@unsaac-horarios.com
- Issues: [GitHub Issues](https://github.com/unsaac/horarios/issues)

---

**Desarrollado con â¤ï¸ para la comunidad UNSAAC**